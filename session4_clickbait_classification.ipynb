{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3dc1cc6-10e3-43e0-9b2a-9c3ab64ca08d",
   "metadata": {},
   "source": [
    "# Clickbait classification\n",
    "This notebook guides you through creating a simple machine learning model to classify clickbait from a **training set** of examples of clickbait and not clickbait."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd1bb16-d13a-488c-800b-5f8fb4f58f27",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6443dda-9967-4c06-8dc9-ef35e1c3c2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install scikit-learn, a machine learning Python package\n",
    "! pip install --user scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857ce0bc-ea9c-4c21-a91a-591e110f85b0",
   "metadata": {},
   "source": [
    "Try importing scikit-learn (the module is called `sklearn`). If it works, great! You can skip down to the next section on loading the clickbait data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775107bc-b1f7-46b0-a5bc-43191c6715d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5736dec-2e61-4429-85a6-4c1942cd55dc",
   "metadata": {},
   "source": [
    "If `sklearn` does not import, try 1) **Kernel > Restart Kernel**. If that doesn't work, try running the following block of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7538e773-31cb-468b-a56d-297e3ecb1934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you get an error importing sklearn, try running this block of code\n",
    "# Modify system PATH environment variable to include installed packages\n",
    "from pathlib import Path \n",
    "import sys \n",
    "\n",
    "home = Path.home()\n",
    "new_path = str(home/'.local/lib/python3.11/site-packages')\n",
    "sys.path.append(new_path)\n",
    "sys.path # new path should include .local/lib/python3.11/site-packages in your home directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc00fe5-945f-4d1a-8089-8fbd3e945426",
   "metadata": {},
   "source": [
    "## Load clickbait data from Kaggle\n",
    "This data consists of headlines classified as clickbait or not (regular news). It is from a dataset on Kaggle, a site where machine learning competitions and datasets are often hosted. Source site: https://www.kaggle.com/datasets/amananandrai/clickbait-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90300de0-f52f-4122-a9bf-551271e1ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset with pandas\n",
    "# 0 corresponds to not clickbait, 1 has been judged as clickbait\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/clickbait_data.csv')\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e8cc3e-5f01-448c-ad24-4522945d4f8a",
   "metadata": {},
   "source": [
    "## Split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0adbeff-1ebf-47b4-a88a-3711794e9681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = int(0.1 * len(data))\n",
    "train, test  = train_test_split(data, test_size=test_size)\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d809d550-dfb8-4182-b288-ae65e56de1d6",
   "metadata": {},
   "source": [
    "## Extract numeric \"features\" from the raw text data\n",
    "This step converts each instance (datapoint, row) of raw text to a numeric vector. No need to worry about the details of this now! We will cover this in the next few class sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f76f8e-26ca-48b4-9a76-21f728f99a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=1, tokenizer=nltk.word_tokenize)\n",
    "vectorizer.fit(train['headline']) # input is a list of strings (documents)\n",
    "train_features = vectorizer.transform(train['headline'])\n",
    "test_features = vectorizer.transform(test['headline'])\n",
    "\n",
    "print(type(train_features))\n",
    "print(train_features.shape) # prints (number of rows in the matrix, number of columns)\n",
    "print(test_features.shape)  # prints (number of rows in the matrix, number of columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc38c76-77ef-4ee3-8e50-eb89176773b1",
   "metadata": {},
   "source": [
    "Note that the input is now a **matrix** with each row as a datapoint (headline) and each column as a numeric feature (don't worry about that now). This is one of the places matrices are used in NLP: as input to machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e00177f-803f-48f5-9e8b-7d3868824978",
   "metadata": {},
   "source": [
    "## Train Naive Bayes model\n",
    "Naive Bayes is a simple machine learning algorithm that we won't be covering in the course. But you know that as a machine learning model, it learns patterns (parameters in a mathematical model) from a training set.\n",
    "\n",
    "That trained model can then be used to make predictions.\n",
    "\n",
    "In our dataset, `train['clickbait']` is the column that contains the **output** we care about: whether the text is clickbait or not. We pass the example input and output in our training set to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c198ab49-a0da-4f44-a241-6acbe9888a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_features, train['clickbait'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54d39fe-5de3-4741-bd96-99148e79e910",
   "metadata": {},
   "source": [
    "## Make predictions from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d939c9-1eb7-4ac5-a3dc-d2575bd2d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an example from the test set\n",
    "# Note that the classifier has never seen this example\n",
    "\n",
    "example = test.sample(1)\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00b72de-4b9e-4c74-8843-99ca65daa1eb",
   "metadata": {},
   "source": [
    "Get the text into a vector format that the classifier can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f6790-5378-4564-afac-3162bef5b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_features = vectorizer.transform(example['headline'])\n",
    "example_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd6f67c-fb44-4a58-a7d2-5e6bcaad9808",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(example_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aab82e-fc87-4602-8f00-9bc48f50cbff",
   "metadata": {},
   "source": [
    "Recall that 0 = not clickbait and 1 = clickbait. **Did the model get it right?** Feel free to re-run the code in this section with other examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
