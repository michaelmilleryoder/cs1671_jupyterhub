{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1976afdf-d3bc-44e7-a217-8527839e4691",
   "metadata": {},
   "source": [
    "# Finetune GPT-2 to talk like Shakespeare\n",
    "\n",
    "Here you will finetune, i.e. continue to train, GPT-2 on a corpus of Shakespeare. GPT-2 was pretrained on contemporary English, but you can prompt your model and see how it replies.\n",
    "\n",
    "References:\n",
    "* https://www.philschmid.de/fine-tune-a-non-english-gpt-2-model-with-huggingface\n",
    "* https://huggingface.co/docs/transformers/en/model_doc/gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2811e35b-deb7-4f1f-a2c4-5dc089b55eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.local/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in ./.local/lib/python3.11/site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in ./.local/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: tf-keras in ./.local/lib/python3.11/site-packages (2.19.0)\n",
      "Requirement already satisfied: transformers[torch] in ./.local/lib/python3.11/site-packages (4.49.0)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.11/site-packages (from transformers[torch]) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in ./.local/lib/python3.11/site-packages (from transformers[torch]) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from transformers[torch]) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.11/site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.local/lib/python3.11/site-packages (from transformers[torch]) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.local/lib/python3.11/site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from transformers[torch]) (4.65.0)\n",
      "Collecting accelerate>=0.26.0 (from transformers[torch])\n",
      "  Downloading accelerate-1.5.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.local/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.11/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.local/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.local/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.local/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.local/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.local/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.local/lib/python3.11/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.local/lib/python3.11/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in ./.local/lib/python3.11/site-packages (from tf-keras) (2.19.0)\n",
      "Requirement already satisfied: psutil in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.local/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.local/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.local/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.local/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.local/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.local/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.local/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./.local/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (5.29.3)\n",
      "Requirement already satisfied: setuptools in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.local/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.local/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.local/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.70.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in ./.local/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in ./.local/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./.local/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in ./.local/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.local/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from requests->transformers[torch]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from requests->transformers[torch]) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.41.2)\n",
      "Requirement already satisfied: rich in ./.local/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in ./.local/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in ./.local/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.14.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.local/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.local/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.0)\n",
      "Downloading accelerate-1.5.2-py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "\u001b[33m  WARNING: The scripts accelerate, accelerate-config, accelerate-estimate-memory, accelerate-launch and accelerate-merge-weights are installed in '/ihome/myoder/mmyoder/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed accelerate-1.5.2\n"
     ]
    }
   ],
   "source": [
    "! pip install --user transformers[torch] torch torchvision torchaudio # tf-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44866bd0-c734-436a-8516-0d46c69eed6e",
   "metadata": {},
   "source": [
    "Now restart your kernel with **Kernel > Restart Kernel**. Test the installation by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c135dde-03da-424d-87b3-356c40d953ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b616921-594e-43ab-8920-a75ee8d43f1b",
   "metadata": {},
   "source": [
    "# Load Shakespeare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32edd47d-d9a0-475b-90f3-639895dab076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load a tokenizer, which specifies the subword tokenization for an LLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d376527-04c4-4a99-bad0-3dd19262d222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 19:18:47.699307: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-18 19:18:47.728322: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742339927.760994   59406 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742339927.770120   59406 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742339927.793459   59406 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742339927.793498   59406 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742339927.793500   59406 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742339927.793502   59406 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-18 19:18:47.802311: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/ihome/myoder/mmyoder/.local/lib/python3.11/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "\n",
    "train_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path='data/shakespeare_train.txt',\n",
    "    block_size=64)\n",
    "\n",
    "test_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path='data/shakespeare_test.txt',\n",
    "    block_size=64)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2276d9c-c760-4b5a-ad30-7eb969251dc0",
   "metadata": {},
   "source": [
    "# Initialize training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beb86495-8b6a-47c6-8d17-d1bd3dacab51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-shakespeare\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=3, # number of training epochs\n",
    "    per_device_train_batch_size=32, # batch size for training\n",
    "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
    "    eval_steps = 300, # Number of update steps between two evaluations.\n",
    "    save_steps=800, # after # steps model is saved \n",
    "    warmup_steps=500,# number of warmup steps for learning rate scheduler\n",
    "    prediction_loss_only=True,\n",
    "    )\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c6c879-a3eb-482a-a453-2dfa04c597cd",
   "metadata": {},
   "source": [
    "# Finetune (train) the model\n",
    "And save it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6595688e-61b0-44ff-83d1-3d49dcdf4227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='547' max='547' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [547/547 02:31, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.499200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=547, training_loss=4.477526091134527, metrics={'train_runtime': 151.4544, 'train_samples_per_second': 115.395, 'train_steps_per_second': 3.612, 'total_flos': 570825105408000.0, 'train_loss': 4.477526091134527, 'epoch': 1.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd20f9e4-dcfc-4935-8795-f2a0d14b4fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model() # this will save to the directory specified in the TrainingArguments object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4bf2b7-c005-4f5b-9fd1-e2018f53b1c8",
   "metadata": {},
   "source": [
    "# Generate text from the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7d8711e-03f4-48d0-b9f2-96b701295d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "shakespeare_gpt2 = pipeline('text-generation', model='./gpt2-shakespeare', tokenizer='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6773b99-df6c-4cbe-9965-fa98cce35576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Please.\\nO, so you do, though you are all of you dead!\\nI have a very large purse for my life; if the poor\\nLet them rest their grief's sighs thereabouts,\\nThe way I have made it\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_gpt2('Please')[0]['generated_text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
